# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0

# This script removes engagement duplicates from APOS based on a customer
# provided CSV file
import asyncio
import csv
import re
from pathlib import Path
from uuid import UUID

import click
import structlog.stdlib
from more_itertools import one
from pydantic import BaseModel

from scripts.common import get_gql_client
from scripts.remove_leave_duplicates import sync_engagement
from sdtoolplus.autogenerated_graphql_client import EngagementFilter
from sdtoolplus.autogenerated_graphql_client import GraphQLClient

logger = structlog.stdlib.get_logger()


class Engagement(BaseModel):
    user_key: str
    uuid: UUID | None


def get_csv_lines(csvfile: Path) -> list[Engagement]:
    engagements = []
    with open(csvfile, "r") as fp:
        lines = csv.reader(fp)
        for eng in list(lines)[1:]:
            user_key, name, url, _ = eng
            match = re.search(r"/engagement/(.*)\?", url)
            eng_uuid = UUID(match.group(1)) if match else None
            engagements.append(Engagement(user_key=user_key[1:], uuid=eng_uuid))
        return engagements


async def remove_duplicate_engagements(
    gql_client: GraphQLClient,
    csvfile: Path,
    dry_run: bool,
) -> None:
    engagements = get_csv_lines(csvfile)
    logger.info("CSV engagements", engagements=engagements)

    for engagement in engagements:
        logger.info(
            "Processing engagement",
            user_key=engagement.user_key,
            uuid=engagement.uuid,
        )

        r_engagements = await gql_client.get_engagement_uuids(
            EngagementFilter(
                user_keys=[engagement.user_key],
                from_date=None,
                to_date=None,
            )
        )
        eng_uuids = [obj.uuid for obj in r_engagements.objects]
        logger.info("Engagements for user_key", engagements=eng_uuids)
        assert len(eng_uuids) == 2, "Not exactly two engagements!"

        if engagement.uuid is not None:
            # Delete the engagement listed in the CSV file
            eng_uuids.remove(engagement.uuid)
            logger.info(
                "Delete engagement",
                user_key=engagement.user_key,
                uuid=engagement.uuid,
            )
            if not dry_run:
                await gql_client.delete_org_function(engagement.uuid)

            eng_to_sync = one(eng_uuids)
            logger.info("Sync engagement", uuid=eng_to_sync)
            if not dry_run:
                await sync_engagement(eng_to_sync)
        else:
            # Delete a random engagement with the given user_key
            eng_uuid1, eng_uuid2 = eng_uuids
            logger.info(
                "Delete engagement",
                user_key=engagement.user_key,
                uuid=eng_uuid1,
            )
            if not dry_run:
                await gql_client.delete_org_function(eng_uuid1)

            logger.info("Sync engagement", uuid=eng_uuid1)
            if not dry_run:
                await sync_engagement(eng_uuid2)


@click.command()
@click.option(
    "--csvfile",
    type=click.Path(exists=True, readable=True),
    help="CSV file for customer containing engagements to delete",
)
@click.option(
    "--dry-run",
    is_flag=True,
    help="Dry run, do not delete engagements",
)
def main(csvfile: Path, dry_run: bool) -> None:
    logger.info("Script started")

    gql_client = get_gql_client()
    asyncio.run(remove_duplicate_engagements(gql_client, csvfile, dry_run))

    logger.info("Script finished")


if __name__ == "__main__":
    main()
